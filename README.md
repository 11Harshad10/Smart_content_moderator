# Smart_content_moderator
Smart Content Moderator is a machine learning-based web application designed to detect and filter toxic or harmful user-generated content. It uses a trained text classification model to assess whether a piece of text contains toxic language. The model is hosted with a simple backend (likely using Flask), and users interact via a web-based interface

# Smart Content Moderator

A machine learning-powered web application for detecting and moderating toxic user-generated content.

## ğŸ’¡ Features

- Detects and classifies toxic comments using a trained ML model
- Simple web-based interface to test content
- REST API for content classification
- Pre-trained vectorizer and classifier using NLP techniques
- Integration-ready backend

## ğŸ§  Model

- The model is trained using NLP techniques on a dataset of toxic and non-toxic comments.
- Vectorization is done using `TfidfVectorizer`.
- Classifier is stored as `toxic_comment_classifier.pkl`.
- Includes Jupyter notebooks for training and testing (`model1.ipynb`, `predictor.ipynb`).

## ğŸ—‚ï¸ Project Structure

Smart_content_Moderator/
â”‚
â”œâ”€â”€ backend.py # API and backend logic
â”œâ”€â”€ Connect.py # Possibly handles database or API integrations
â”œâ”€â”€ model1.ipynb # Model training notebook
â”œâ”€â”€ predictor.ipynb # Prediction logic and experiments
â”œâ”€â”€ test_api.py # Script to test the backend API
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ index.html # Web interface
â”œâ”€â”€ toxic_comment_classifier.pkl # Trained classifier
â”œâ”€â”€ vectorizer.pkl # Fitted TF-IDF vectorizer
â””â”€â”€ client_secret_...json # Google API credentials (DO NOT SHARE)
